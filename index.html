<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="Bridging High-Quality Audio and Video via Language for Sound Effects Retrieval from Visual Queries"/>
  <meta property="og:description" content="WASPAA 2023"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Bridging High-Quality Audio and Video via Language for Sound Effects Retrieval from Visual Queries">
  <meta name="twitter:description" content="Appearing at WASPAA 2023">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
<!--   <meta name="twitter:image" content="static/images/your_twitter_banner_image.png"> -->
<!--   <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="sound effects, retrieval, audio-visual, data generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Bridging High-Quality Audio and Video via Language for Sound Effects Retrieval from Visual Queries</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Bridging High-Quality Audio and Video via Language for Sound Effects Retrieval from Visual Queries</h1>
            <span class="author-block">WASPAA 2023</span>

            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://juliawilkins.github.io/" target="_blank">Julia Wilkins</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.justinsalamon.com/" target="_blank">Justin Salamon</a><sup>2</sup>,
              </span>
                <span class="author-block">
                  <a href="https://magdalenafuentes.github.io/" target="_blank">Magdalena Fuentes</a><sup>1</sup>,
                </span>
                <span class="author-block">
                  <a href="https://engineering.nyu.edu/faculty/juan-pablo-belloK" target="_blank">Juan Pablo Bello</a><sup>1</sup>,
                </span>
                <span class="author-block">
                  <a href="https://www.urinieto.com/about/" target="_blank">Oriol Nieto</a><sup>2</sup>,
                </span>
              </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Music and Audio Research Lab, New York University</span>
                    <br>
                    <span class="author-block"><sup>2</sup>Adobe Research</span>

                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2308.09089.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered">
        <p></p>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/oxzpYHdrpko" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
      </div>
      </div>
</div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered">

        <table style="width: 100%"">
          <colgroup>
            <col span="1" style="width: 100%;">
            <col span="1" style="width: 20%;">
            <col span="1" style="width: 20%">
         </colgroup>

          <tr>
              <th><center>Input Video Frame</center></th>
              <th><center>Our Retrieved Audio</center></th>
              <th><center>Wav2CLIP (Baseline) Retrieved Audio</center></th>
          </tr>
          <!-- LION -->
          <tr>
              <td> <center></center><img src="static/examples_companion_web_v2/lion/lion.png" alt="Image 1"></center></td>
              <td>
                <center>
                    <audio controls>
                      <source src="static/examples_companion_web_v2/lion/ours/aud1.wav" type="audio/wav">
                      Your browser does not support the audio element.
                  </audio>
                  <audio controls>
                      <source src="static/examples_companion_web_v2/lion/ours/aud2.wav" type="audio/wav">
                      Your browser does not support the audio element.
                  </audio>
                  <audio controls>
                      <source src="static/examples_companion_web_v2/lion/ours/aud3.wav" type="audio/wav">
                      Your browser does not support the audio element.
                  </audio>
                </center>
              </td>
           
              <td>
                <center>
                <audio controls>
                    <source src="static/examples_companion_web_v2/lion/w2c/aud1.wav" type="audio/wav">
                    Your browser does not support the audio element.
                </audio>
                <audio controls>
                    <source src="static/examples_companion_web_v2/lion/w2c/aud2.wav" type="audio/wav">
                    Your browser does not support the audio element.
                </audio>
                <audio controls>
                    <source src="static/examples_companion_web_v2/lion/w2c/aud3.wav" type="audio/wav">
                    Your browser does not support the audio element.
                </audio>
              </center>
            </td>
          </tr>
  
          <!-- GUN-->
          <tr>
            <td> <img src="static/examples_companion_web_v2/gun/gun.png" alt="Image 1"></td>
            <td><center>
                <audio controls>
                    <source src="static/examples_companion_web_v2/gun/ours/aud1.wav" type="audio/wav">
                    Your browser does not support the audio element.
                </audio>
                <audio controls>
                    <source src="static/examples_companion_web_v2/gun/ours/aud2.wav" type="audio/wav">
                    Your browser does not support the audio element.
                </audio>
                <audio controls>
                    <source src="static/examples_companion_web_v2/gun/ours/aud3.wav" type="audio/wav">
                    Your browser does not support the audio element.
                </audio>
              </center>
            </td>
            <td>
              <center>
              <audio controls>
                  <source src="static/examples_companion_web_v2/gun/w2c/aud1.wav" type="audio/wav">
                  Your browser does not support the audio element.
              </audio>
              <audio controls>
                  <source src="static/examples_companion_web_v2/gun/w2c/aud2.wav" type="audio/wav">
                  Your browser does not support the audio element.
              </audio>
              <audio controls>
                  <source src="static/examples_companion_web_v2/gun/w2c/aud3.wav" type="audio/wav">
                  Your browser does not support the audio element.
              </audio>
            </center>
          </td>
        </tr>
  
        <!-- LIGHTNING -->
        <tr>
          <td> <img src="static/examples_companion_web_v2/lightning/lightning.png"  alt="Image 1"></td>
          <td>
            <center>
              <audio controls>
                  <source src="static/examples_companion_web_v2/lightning/ours/aud1.wav" type="audio/wav">
                  Your browser does not support the audio element.
              </audio>
              <audio controls>
                  <source src="static/examples_companion_web_v2/lightning/ours/aud2.wav" type="audio/wav">
                  Your browser does not support the audio element.
              </audio>
              <audio controls>
                  <source src="static/examples_companion_web_v2/lightning/ours/aud3.wav" type="audio/wav">
                  Your browser does not support the audio element.
              </audio>
            </center>
          </td>
          <td>
            <center>
            <audio controls>
                <source src="static/examples_companion_web_v2/lightning/w2c/aud1.wav" type="audio/wav">
                Your browser does not support the audio element.
            </audio>
            <audio controls>
                <source src="static/examples_companion_web_v2/lightning/w2c/aud2.wav" type="audio/wav">
                Your browser does not support the audio element.
            </audio>
            <audio controls>
                <source src="static/examples_companion_web_v2/lightning/w2c/aud3.wav" type="audio/wav">
                Your browser does not support the audio element.
            </audio>
          </center>
        </td>
      </tr>

      <!-- WATERFALL -->
      <tr>
        <td> <img src="static/examples_companion_web_v2/waterfall/waterfall.png" alt="Image 1" width=""></td>
        <td>
          <center>
            <audio controls>
                <source src="static/examples_companion_web_v2/waterfall/ours/aud1.wav" type="audio/wav">
                Your browser does not support the audio element.
            </audio>
            <audio controls>
                <source src="static/examples_companion_web_v2/waterfall/ours/aud2.wav" type="audio/wav">
                Your browser does not support the audio element.
            </audio>
            <audio controls>
                <source src="static/examples_companion_web_v2/waterfall/ours/aud3.wav" type="audio/wav">
                Your browser does not support the audio element.
            </audio>
          </center>
        </td>
        <td>
          <center>
          <audio controls>
              <source src="static/examples_companion_web_v2/waterfall/w2c/aud1.wav" type="audio/wav">
              Your browser does not support the audio element.
          </audio>
          <audio controls>
              <source src="static/examples_companion_web_v2/waterfall/w2c/aud2.wav" type="audio/wav">
              Your browser does not support the audio element.
          </audio>
          <audio controls>
              <source src="static/examples_companion_web_v2/waterfall/w2c/aud3.wav" type="audio/wav">
              Your browser does not support the audio element.
          </audio>
        </center>
      </td>
    </tr>
  
      </table>
      
    </div>
    <p>
      Baseline used: <a href="https://github.com/descriptinc/lyrebird-wav2clip" target="_blank">Wav2CLIP</a>
    </p>
    <p>
      Audio credits: <a href="https://www.adobe.com/products/audition/offers/AdobeAuditionDLCSFX.html" target="_blank">Adobe Audition Sound Effects</a>
    </p>
    <p>
      Video credits: <a href="https://www.pexels.com/" target="_blank">Pexels</a>
    </p>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Finding the right sound effects (SFX) to match moments in a video is a difficult and time-consuming task, and relies heavily on the quality and completeness of text metadata. Retrieving high-quality (HQ) SFX using a video frame directly as the query is an attractive alternative, removing the reliance on text metadata and providing a low barrier to entry for non-experts. Due to the lack of HQ audio-visual training data, previous work on audio-visual retrieval relies on YouTube (``in-the-wild‚Äù) videos of varied quality for training, where the audio is often noisy and the video of amateur quality. As such it is unclear whether these systems would generalize to the task of matching HQ audio to production-quality video. To address this, we propose a multimodal framework for recommending HQ SFX given a video frame by (1) leveraging large language models and foundational vision-language models to bridge HQ audio and video to create audio-visual pairs, resulting in a highly scalable automatic audio-visual data curation pipeline; and (2) using pre-trained audio and visual encoders to train a contrastive learning-based retrieval system. We show that our system, trained using our automatic data curation pipeline, significantly outperforms baselines trained on in-the-wild data on the task of HQ SFX retrieval for video. Furthermore, while the baselines fail to generalize to this task, our system generalizes well from clean to in-the-wild data, outperforming the baselines on a dataset of YouTube videos despite only being trained on the HQ audio-visual pairs. A user study confirms that people prefer SFX retrieved by our system over the baseline 67% of the time both for HQ and in-the-wild data. Finally, we present ablations to determine the impact of model and data pipeline design choices on downstream retrieval performance. Please visit our companion website to listen to and view our SFX retrieval results.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/> -->
<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">System Overview</h2>
          <div class="content has-text-justified">
        
        <img src="static/images/block_diag.png" alt="Overview of system"/>
        <p>Our proposed system, shown above, contains two core components: </p>
        <ol>
          <li><b>Automatic HQ Audio-Visual Data Curation Pipeline</b>:  To overcome to challenge of a lack of high-quality audio-visual data,
            we propose a highly scalable audio-visual data curation pipeline that leverages large language models and 
            foundational vision-language models to bridge HQ audio and video to create audio-visual pairs. We use <a href="https://huggingface.co/bigscience/bloom">Bloom</a>
            to enhance SFX text metadata and <a href="https://arxiv.org/abs/2103.00020">CLIP</a> to retrieve relevant video frames 
            given an LLM-enhanced text query, such that we can create new audio-visual pairs for (2). 
          
          </li>
          <li><b>Contrastive Learning Training</b>: Using our HQ audio-visual data pairs created in (1), 
            we train a contrastive learning model to create a joint embedding space for audio and visual data.
            Using a standard contrastive loss, we fine-tune a pre-trained <a href="https://arxiv.org/abs/1912.10211">PANNS</a> audio encoder 
            to project an audio signal into the original CLIP image embedding space. This allows us to retrieve relevant sound effects given an input visual query, or vice-versa.
          
          </li>

        </ol>
      </div>
      </div>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Results</h2>
          <div class="content has-text-justified">

        <p>We evaluate our system against two strong pre-trained baselines capable of performing audio retrieval given a visual query: <a href="https://arxiv.org/abs/2110.11499" target="_blank">Wav2CLIP</a> and <a href="https://arxiv.org/abs/2106.13043">AudioCLIP</a>.
          We evaluate our proposed method and the baselines on three test sets (1) <b>PSE-Test</b>  <a href="https://www.prosoundeffects.com/">PSE Sound Effects</a> paired with Adobe Stock Videos, generated using our proposed 
          data curation pipeline, (2) <b>ASFX-Test</b>: <a href="https://www.adobe.com/products/audition/offers/AdobeAuditionDLCSFX.html" target="_blank">Adobe Audition Sound Effects</a> paired with Adobe Stock videos, generated
          using our proposed data curation pipeline, and (3) <b>AVE-Test</b>: A <a href="https://sites.google.com/view/audiovisualresearch"> dataset</a> containing
          real audio-visual pairs, i.e. "in-the-wild" videos. The results are shown below: 

        </p>
       <center><img src="static/images/results.png" alt="Image 1" width=70%></center></td>
       <p>
        Our best model significantly outperforms the baselines across all three test sets. 
        The results indicate two important takeaways: first, that our model is superior at matching HQ SFX to production quality video, our target application, 
        as indicated by the results on PSE-Test and ASFX-Test. Second, and more surprising,
         our model successfully generalizes to noisy in-the-wild data, represented by AVE-Test, which is particularly interesting for our model trained 
         from scratch as it was trained with only HQ auto-curated audio-visual pairs. 
         Conversely, the baselines, which were trained on large in-the-wild video collections,
        fail to generalize to the clean audio-visual data. 
        This validates our proposed data curation pipeline as useful for training models that generalize to both clean HQ data and noisy in-the-wild data.
       </p>

       <p>
        <b>User Study</b>: We also perform a user study to validate our results qualitatively. We surveyed 
        28 users who each evaluated 30 comparisons of our retrieved SFX given a visual query versus the baseline, yielding 840 total unique comparisons.
        We found that participants preferred the SFX recommended by our model over the baseline 68.1% and 66.4% of the time for data from PSE-Test and AVE-Test, respectively.
       </p>
      </div>
      </div>
      </div>
  </div>
</div>
</div>
</section>


<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\ -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title is-3">Citation</h2>
      <pre><code>@inproceedings{wilkins2023sfx,
        title={Bridging High-Quality Audio and Video via Language for Sound Effects Retrieval from Visual Queries},
        author={Wilkins, Julia and Salamon, Justin and Fuentes, Magdalena and Bello, Juan Pablo, and Nieto, Oriol},
        booktitle={2023 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)},
        year={2023},
        organization={IEEE}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
